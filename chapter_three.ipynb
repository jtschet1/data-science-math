{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Descriptive Versus Inferential Statistics **\n",
    "- Descriptive statistics is the branch of statistics that deals with the collection, organization, and presentation of data. It is used to describe and summarize data.\n",
    "- Inferential statistics is the branch of statistics that deals with making predictions or inferences about a population based on a sample of data. It is used to draw conclusions about a population based on a sample of data.\n",
    "\n",
    "** Populations, Samples, and Bias **\n",
    "- A population is the entire group of individuals or items that we are interested in studying.\n",
    "- A sample is a subset of the population that we collect data from.\n",
    "- Bias is the tendency for a sample to differ from the population in a systematic way.\n",
    "\n",
    "\n",
    "** Descriptive Statistics **\n",
    "- Descriptive statistics are used to summarize and describe the main features of a dataset.\n",
    "- Common descriptive statistics include measures of central tendency (mean, median, mode), measures of dispersion (range, variance, standard deviation), and measures of shape (skewness, kurtosis).\n",
    "- Descriptive statistics can be used to summarize the data in a meaningful way and to identify patterns and trends in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean and Weighted Mean**\n",
    "- The mean is the average of a set of numbers. It is calculated by adding up all the numbers in the set and dividing by the total number of numbers.\n",
    "- The weighted mean is a type of mean that takes into account the weights of the numbers in the set. It is calculated by multiplying each number by its weight, adding up the weighted numbers, and dividing by the total weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pets each person owns\n",
    "sample = [1, 3, 2, 5, 7, 0, 2, 3]\n",
    "mean = sum(sample) / len(sample)\n",
    "print(mean) # prints 2.875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3-2. Calculating a weighted mean in Python\n",
    "# Three exams of .20 weight each and final exam of .40 weight\n",
    "sample = [90, 80, 63, 87]\n",
    "weights = [.20, .20, .20, .40]\n",
    "weighted_mean = sum(s * w for s,w in zip(sample, weights)) / sum(weights)\n",
    "print(weighted_mean) # prints 81.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three exams of .20 weight each and final exam of .40 weight\n",
    "sample = [90, 80, 63, 87]\n",
    "weights = [1.0, 1.0, 1.0, 2.0]\n",
    "weighted_mean = sum(s * w for s,w in zip(sample, weights)) / sum(weights)\n",
    "print(weighted_mean) # prints 81.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Median **\n",
    "- The median is the middle value of a set of numbers when they are arranged in order. If there is an even number of values, the median is the average of the two middle values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Number of pets each person owns\n",
    "sample = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def median(values):\n",
    "    ordered = sorted(values)\n",
    "    print(ordered)\n",
    "    n = len(ordered)\n",
    "    mid = int(n / 2) - 1 if n % 2 == 0 else int(n/2)\n",
    "    if n % 2 == 0:\n",
    "        2.0\n",
    "    else:\n",
    "        return ordered[mid]\n",
    "print(median(sample)) # prints 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mode **\n",
    "- The mode is the value that appears most frequently in a set of numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pets each person owns\n",
    "from collections import defaultdict\n",
    "sample = [1, 3, 2, 5, 7, 0, 2, 3]\n",
    "\n",
    "def mode(values):\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for s in values:\n",
    "        counts[s] += 1\n",
    "    max_count = max(counts.values())\n",
    "    modes = [v for v in set(values) if counts[v] == max_count]\n",
    "    return modes\n",
    "print(mode(sample)) # [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance and Standard Deviation\n",
    "- Variance is a measure of how spread out the numbers in a dataset are. It is calculated by taking the average of the squared differences between each number and the mean.\n",
    "- Standard deviation is the square root of the variance. It is a measure of how spread out the numbers in a dataset are, with a larger standard deviation indicating a greater spread.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Number of pets each person owns\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "def variance(values):\n",
    "    mean = sum(values) / len(values)\n",
    "    _variance = sum((v - mean) ** 2 for v in values) / len(values)\n",
    "    return _variance\n",
    "\n",
    "print(variance(data)) # prints 21.387755102040813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# Number of pets each person owns\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "def variance(values):\n",
    "    mean = sum(values) / len(values)\n",
    "    _variance = sum((v - mean) ** 2 for v in values) / len(values)\n",
    "    return _variance\n",
    "\n",
    "def std_dev(values):\n",
    "    return sqrt(variance(values))\n",
    "\n",
    "print(std_dev(data)) # prints 4.624689730353898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# Number of pets each person owns\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "def variance(values, is_sample: bool = False):\n",
    "    mean = sum(values) / len(values)\n",
    "    _variance = sum((v - mean) ** 2 for v in values) /\n",
    "    (len(values) - (1 if is_sample else 0))\n",
    "    return _variance\n",
    "\n",
    "def std_dev(values, is_sample: bool = False):\n",
    "    return sqrt(variance(values, is_sample))\n",
    "\n",
    "print(\"VARIANCE = {}\".format(variance(data, is_sample=True))) # 24.95238095238095\n",
    "print(\"STD DEV = {}\".format(std_dev(data, is_sample=True))) # 4.99523582550223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Distribution\n",
    "- The normal distribution is a bell-shaped distribution that is symmetrical around the mean. It is characterized by two parameters: the mean and the standard deviation.\n",
    "- The normal distribution is important in statistics because many natural phenomena follow this distribution, and it is used in many statistical tests and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_pdf(x: float, mean: float, std_dev: float) -> float:\n",
    "    return (1.0 / (2.0 * math.pi * std_dev ** 2) ** 0.5) *\n",
    "\n",
    "math.exp(-1.0 * ((x - mean) ** 2 / (2.0 * std_dev ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF)\n",
    "- The cumulative distribution function (CDF) is a function that gives the probability that a random variable takes on a value less than or equal to a given value.\n",
    "- The CDF is used to calculate probabilities for continuous random variables and is an important concept in probability theory and statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "mean = 64.43\n",
    "std_dev = 2.99\n",
    "x = norm.cdf(64.43, mean, std_dev)\n",
    "print(x) # prints 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The Inverse CDF **\n",
    "- The inverse cumulative distribution function (inverse CDF) is the function that gives the value of a random variable for a given probability.\n",
    "- The inverse CDF is used to calculate quantiles for continuous random variables and is an important concept in probability theory and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "x = norm.ppf(.95, loc=64.43, scale=2.99)\n",
    "print(x) # 69.3481123445849"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats import norm\n",
    "    for i in range(0,1000):\n",
    "    random_p = random.uniform(0.0, 1.0)\n",
    "    random_weight = norm.ppf(random_p, loc=64.43, scale=2.99)\n",
    "    print(random_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Z-Scores **\n",
    "- A z-score is a measure of how many standard deviations a data point is from the mean of a dataset.\n",
    "- Z-scores are used to standardize data and compare data points from different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    return (x - mean) / std\n",
    "\n",
    "def z_to_x(z, mean, std):\n",
    "    return (z * std) + mean\n",
    "\n",
    "mean = 140000\n",
    "std_dev = 3000\n",
    "x = 150000\n",
    "# Convert to Z-score and then back to X\n",
    "z = z_score(x, mean, std_dev)\n",
    "back_to_x = z_to_x(z, mean, std_dev)\n",
    "print(\"Z-Score: {}\".format(z)) # Z-Score: 3.333\n",
    "print(\"Back to X: {}\".format(back_to_x)) # Back to X: 150000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Inferential Statistics **\n",
    "- Inferential statistics are used to make predictions or inferences about a population based on a sample of data.\n",
    "- Common inferential statistics include hypothesis testing, confidence intervals, and regression analysis.\n",
    "- Inferential statistics are used to draw conclusions about a population based on a sample of data and to make predictions about future outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The Central Limit Theorem **\n",
    "- The central limit theorem states that the sampling distribution of the sample mean will be approximately normally distributed, regardless of the shape of the population distribution, as long as the sample size is large enough.\n",
    "- The central limit theorem is important in statistics because it allows us to make inferences about a population based on a sample of data, even if the population distribution is not normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import plotly.express as px\n",
    "sample_size = 31\n",
    "sample_count = 1000\n",
    "# Central limit theorem, 1000 samples each with 31\n",
    "# random numbers between 0.0 and 1.0\n",
    "x_values = [(sum([random.uniform(0.0, 1.0) for i in range(sample_size)]) / \\\n",
    "sample_size)\n",
    "    for _ in range(sample_count)]\n",
    "y_values = [1 for _ in range(sample_count)]\n",
    "px.histogram(x=x_values, y = y_values, nbins=20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Confidence Intervals **\n",
    "- A confidence interval is a range of values that is likely to contain the true value of a population parameter.\n",
    "- Confidence intervals are used to estimate the precision of a sample estimate and to make inferences about a population based on a sample of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(-1.959963984540054), np.float64(1.959963984540054))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "def critical_z_value(p):\n",
    "    norm_dist = norm(loc=0.0, scale=1.0)\n",
    "    left_tail_area = (1.0 - p) / 2.0\n",
    "    upper_area = 1.0 - ((1.0 - p) / 2.0)\n",
    "    return norm_dist.ppf(left_tail_area), norm_dist.ppf(upper_area)\n",
    "print(critical_z_value(p=.95))\n",
    "# (-1.959963984540054, 1.959963984540054)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "def critical_z_value(p):\n",
    "    norm_dist = norm(loc=0.0, scale=1.0)\n",
    "    left_tail_area = (1.0 - p) / 2.0\n",
    "    upper_area = 1.0 - ((1.0 - p) / 2.0)\n",
    "    return norm_dist.ppf(left_tail_area), norm_dist.ppf(upper_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(63.68635915701992), np.float64(65.12964084298008))\n"
     ]
    }
   ],
   "source": [
    "def confidence_interval(p, sample_mean, sample_std, n):\n",
    "    # Sample size must be greater than 30\n",
    "    lower, upper = critical_z_value(p)\n",
    "    lower_ci = lower * (sample_std / sqrt(n))\n",
    "    upper_ci = upper * (sample_std / sqrt(n))\n",
    "    return sample_mean + lower_ci, sample_mean + upper_ci\n",
    "print(confidence_interval(p=.95, sample_mean=64.408, sample_std=2.05, n=31))\n",
    "# (63.68635915701992, 65.12964084298008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding P-Values\n",
    "When we say something is statistically significant, what do we mean by that? We hear\n",
    "it used loosely and frequently but what does it mean mathematically? Technically, it\n",
    "has to do with something called the p-value, which is a hard concept for many folks\n",
    "to grasp. But I think the concept of p-values makes more sense when you trace it back\n",
    "to its invention. While this is an imperfect example, it gets across some big ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Testing\n",
    "Past studies have shown that the mean recovery time for a cold is 18 days, with a\n",
    "standard deviation of 1.5 days, and follows a normal distribution\n",
    "You have a new drug that you think will reduce the recovery time for a cold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9544997361036416\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "# Cold has 18 day mean recovery, 1.5 std dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "# 95% probability recovery time takes between 15 and 21 days.\n",
    "x = norm.cdf(21, mean, std_dev) - norm.cdf(15, mean, std_dev)\n",
    "print(x) # 0.9544997361036416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09121121972586788\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "# Cold has 18 day mean recovery, 1.5 std dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "# Probability of 16 or less days\n",
    "p_value = norm.cdf(16, mean, std_dev)\n",
    "print(p_value) # 0.09121121972586788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Two-Tailed Test **\n",
    "- A two-tailed test is a statistical test in which the null hypothesis is rejected if the test statistic is either significantly greater than or significantly less than the critical value.\n",
    "- A two-tailed test is used when the alternative hypothesis is that the population parameter is not equal to a specified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.060054023189918\n",
      "20.93994597681008\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "# Cold has 18 day mean recovery, 1.5 std dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "# What x-value has 2.5% of area behind it?\n",
    "x1 = norm.ppf(.025, mean, std_dev)\n",
    "# What x-value has 97.5% of area behind it\n",
    "x2 = norm.ppf(.975, mean, std_dev)\n",
    "print(x1) # 15.060054023189918\n",
    "print(x2) # 20.93994597681008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18242243945173575\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "# Cold has 18 day mean recovery, 1.5 std dev\n",
    "mean = 18\n",
    "std_dev = 1.5\n",
    "# Probability of 16 or less days\n",
    "p1 = norm.cdf(16, mean, std_dev)\n",
    "# Probability of 20 or more days\n",
    "p2 = 1.0 - norm.cdf(20, mean, std_dev)\n",
    "# P-value of both tails\n",
    "p_value = p1 + p2\n",
    "print(p_value) # 0.18242243945173575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.063898561628021 2.0638985616280205\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "# get critical value range for 95% confidence\n",
    "# with a sample size of 25\n",
    "n = 25\n",
    "lower = t.ppf(.025, df=n-1)\n",
    "upper = t.ppf(.975, df=n-1)\n",
    "print(lower, upper)\n",
    "# -2.063898561628021 2.0638985616280205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Data Considerations and the\n",
    "Texas Sharpshooter Fallacy\n",
    "- The Texas sharpshooter fallacy is a logical fallacy in which a person cherry-picks data after the fact to suit their argument or hypothesis.\n",
    "- The Texas sharpshooter fallacy is a common mistake in data analysis and can lead to incorrect conclusions and biased results.\n",
    "- To avoid the Texas sharpshooter fallacy, it is important to define the hypothesis or research question before collecting and analyzing data and to use appropriate statistical methods to test the hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maths",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
